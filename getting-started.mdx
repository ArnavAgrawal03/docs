---
title: "Getting Started"
description: "Setting Up the Morphik server"
---

# Installation Options

<Tabs>
  <Tab title="Direct Installation">
    ## Direct Installation

    ### Prerequisites

    <Accordion title="Python">
      Please ensure that you have Python 3.12 installed on your machine. Guides for installing Python can be found on the [Python website](https://www.python.org/downloads/release/python-3129/).
    </Accordion>

    <Accordion title="PostgreSQL">
      Morphik requires PostgreSQL with the pgvector extension for vector storage and similarity search capabilities. Follow the installation instructions for your operating system:

      <Tabs>
        <Tab title="macOS">
          On macOS, you can use Homebrew to install PostgreSQL and pgvector:

          ```bash
          brew install postgresql@14
          brew install pgvector
          ```

          Start the PostgreSQL service:

          ```bash
          brew services start postgresql@14
          ```

          Create a database and user for DataBridge:

          ```bash
          createdb databridge
          createuser -s postgres
          ```

          These commands create a database named "databridge" and a superuser named "postgres" that the application will use to connect.
        </Tab>
        <Tab title="Ubuntu/Debian">
          Install PostgreSQL from the official repositories.**We recommend version 14** . Other versions may work, but haven't been extensively tested!

          ```bash
          sudo apt update
          sudo apt install postgresql postgresql-contrib
          ```

          Install pgvector by building from source:

          ```bash
          git clone https://github.com/pgvector/pgvector.git
          cd pgvector
          make
          sudo make install
          ```

          Start and enable the PostgreSQL service:

          ```bash
          sudo systemctl start postgresql
          sudo systemctl enable postgresql
          ```

          Create a database and user for DataBridge:

          ```bash
          sudo -u postgres createdb databridge
          sudo -u postgres createuser -s postgres
          ```
        </Tab>
        <Tab title="Windows">
          1. Download and install PostgreSQL from the [official website](https://www.postgresql.org/download/windows/).
          2. During installation, make note of the password you set for the postgres user.
          3. Install pgvector:
             - Open pgAdmin (installed with PostgreSQL)
             - Connect to your PostgreSQL server
             - Right-click on "Extensions" and select "Create \> Extension"
             - Select "pgvector" from the dropdown and click "Save"
          4. Create a database for DataBridge:
             - Right-click on "Databases" and select "Create \> Database"
             - Name it "databridge" and click "Save"
        </Tab>
      </Tabs>

      After installation, verify that PostgreSQL is running correctly:

      ```bash
      psql -U postgres -c "SELECT version();"
      ```

      You should see the following output:

      ```
       version                                                            
      ------------------------------------------------------------------------------------------------------------------------------
      <Your postgres version and some compilation details>
      ```
    </Accordion>

    <Accordion title="Additional Dependencies">
      Some system-level dependencies might be required for processing various document types:

      <Tabs>
        <Tab title="macOS">
          ```bash
          # Install via Homebrew
          brew install poppler tesseract libmagic
          ```
        </Tab>
        <Tab title="Ubuntu/Debian">
          ```bash
          # Install via apt
          sudo apt-get update
          sudo apt-get install -y poppler-utils tesseract-ocr libmagic-dev
          ```
        </Tab>
        <Tab title="Windows">
          For Windows, you may need to install these dependencies manually:

          1. **Poppler**: Download from [poppler for Windows](https://github.com/oschwartz10612/poppler-windows/releases/)
          2. **Tesseract**: Download the installer from [UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki)
          3. **libmagic**: This is included in the python-magic-bin package which will be installed with pip
        </Tab>
      </Tabs>
      If you encounter database initialization issues within Docker, you may need to manually initialize the schema:

      ```bash
      psql -U postgres -d databridge -a -f init.sql
      ```
    </Accordion>

    <Accordion title="Installing Ollama">
      <Tabs>
        <Tab title="macOS">
          Install Ollama using Homebrew:

          ```bash
          brew install ollama
          ```

          Start Ollama:

          ```bash
          ollama serve
          ```

          Pull a model to use with Morphik (in a new terminal):

          ```bash
          ollama pull llama3.2
          ```
        </Tab>
        <Tab title="Linux">
          Install Ollama using the official installation script:

          ```bash
          curl -fsSL https://ollama.com/install.sh | sh
          ```

          Start Ollama:

          ```bash
          ollama serve
          ```

          Pull a model to use with Morphik (in a new terminal):

          ```bash
          ollama pull llama3.2
          ```
        </Tab>
        <Tab title="Windows">
          1. Download the Ollama installer from the [official website](https://ollama.com/download/windows).
          2. Run the installer and follow the on-screen instructions.
          3. After installation, Ollama will start automatically.
          4. Open Command Prompt or PowerShell and pull a model:

             ```bash
             ollama pull llama3.2
             ```
        </Tab>
      </Tabs>
    </Accordion>

    ### Cloning the Repository

    To get started with Morphik, we need to first setup the server. This involves cloning the [repository](https://github.com/morphik-org/morphik-core/), installing the dependencies, and the running the server. You are just a few steps away from accurate, agentic RAG over your multi-modal data!

    First, let's clone the repository from GitHub.

    ```bash
    git clone https://github.com/morphik-org/morphik-core.git
    ```

    After cloning the repository, you will notice a `morphik-core` folder in your current directory.

    ```bash
    ls morphik-core
    ```

    If you see an error like `ls: morphik-core: No such file or directory`, it means that the repository is not cloned properly. Please try again.

    Once you have cloned the repository, navigate into the `morphik-core` folder.

    ```bash
    cd morphik-core
    ```

    Next, you need to set up a virtual environment called `.venv`.

    ### Setting Up the Environment

    #### Installing Python Dependencies
    <Note>
    While it is not required, we highly recommend using a virtual environment to ensure dependencies from other projects do not conflict with Morphik. You may use managers like `uv` or `poetry`, but for this guide, we will use the built-in `venv` module.

    Morphik currently supports Python 3.12 as the latest version. We recommend using Python 3.12 for optimal compatibility.
    </Note>

    ```bash
    python3.12 -m venv .venv
    ```

    Now, you need to activate the virtual environment. The activation command differs based on your operating system.

    <Tabs>
      <Tab title="Linux/macOS">
        ```bash
        source .venv/bin/activate
        ```    
      </Tab>
      <Tab title="Windows (Command Prompt)">
        ```bash
        .venv\Scripts\activate.bat
        ```
      </Tab>
      <Tab title="Windows (PowerShell)">
        ```bash
        .venv\Scripts\Activate.ps1
        ```

        If you encounter execution policy errors in PowerShell, you may need to run:

        ```bash
        Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
        ```
      </Tab>
    </Tabs>

    After activation, your command prompt should be prefixed with `(.venv)`, indicating that the virtual environment is active. Once your virtual environment is activated, you can install the required dependencies.

    ```bash
    pip install -r requirements.txt
    ```

    #### Python Dependencies for Document Processing

    You may also need additional Python packages or NLTK resources for processing various document types:

    ```bash
    # If using Python 3.12+, you might need a specific version of unstructured
    pip install unstructured==0.16.10

    # Download required NLTK resources
    python -m nltk.downloader averaged_perceptron_tagger punkt
    ```

    #### Setting up the Server Parameters

    At this point, you may want to customize the server - such as use a different model, enable or disable certain features, etc. - you can do so by editing the `databridge.toml` file. 
    
    Morphik now uses a registered models approach, which allows you to define hundreds of different models in one place and reference them throughout your configuration. This makes it easy to mix and match models based on your needs (e.g., smaller models for simpler tasks). You can find more details about configuration [here](/configuration).

    Morphik uses environment variables to manage secrets and API keys. In order to ensure that any pre-set keys are available to the server, copy the `.env.example` file to `.env`:

    ```bash
    cp .env.example .env
    ```

    In case you're using external models like OpenAI or Anthropic Claude, you'll need to edit the `.env` file with the necessary API keys. Finally, you can run the setup script to install dependencies and setup the database and vector store. 

    ```bash
    python quick_setup.py
    ```

    ### Launching the Server

    You are now ready to launch the Morphik server! Just run the following command to start the server.

    ```bash
    python start_server.py
    ```

    You should see the following output:

    ```
    INFO:     Started server process [15169]
    INFO:     Waiting for application startup.
    INFO:     Application startup complete.
    INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)
    ```

    This means that the server is running on `http://localhost:8000`. You can now interact with the server using the API or the Python SDK.
  </Tab>
  <Tab title="Docker">
    ## Using Docker

    Morphik provides a streamlined Docker-based setup that includes all necessary components: the core API, PostgreSQL with pgvector, and Ollama for AI models.

    ### Prerequisites

    - Docker and Docker Compose installed on your system
    - At least 10GB of free disk space (for models and data)
    - 8GB+ RAM recommended

    ### Quick Start

    1. Clone the repository and navigate to the project directory:
    ```bash
    git clone https://github.com/morphik-org/morphik-core.git
    cd morphik-core
    ```

    2. First-time setup:
    
    If you want to use Ollama for AI capabilities (recommended for local development):
    ```bash
    docker compose --profile ollama up --build -d
    ```

    Or if you're using OpenAI API (configure API key in .env):
    ```bash
    docker compose up --build
    ```

    These commands will:
    - Build all required containers
    - Download necessary AI models (nomic-embed-text and llama3.2 if using Ollama)
    - Initialize the PostgreSQL database with pgvector
    - Start all services

    The initial setup may take 5-10 minutes depending on your internet speed, as it needs to download the AI models.
    
    > **Note**: When using Ollama, ensure your system has sufficient memory. The llama3.2 model requires at least 4GB of available RAM. If you encounter memory issues, you can increase Docker's memory allocation in Docker Desktop settings (Resources > Advanced > Memory), modify the `databridge.toml` file to use a smaller model, or switch to using OpenAI API.

    3. For subsequent runs:
    ```bash
    docker compose up    # Start all services
    docker compose down  # Stop all services
    ```

    4. To completely reset (will delete all data and models):
    ```bash
    docker compose down -v
    ```

    ### Configuration

    The default configuration works out of the box and includes:
    - PostgreSQL with pgvector for document storage
    - Ollama for AI models (embeddings and completions)
    - Local file storage
    - Basic authentication

    You can customize your setup by creating a `.env` file:

    ```bash
    JWT_SECRET_KEY=your-secure-key-here  # Important: Change in production
    OPENAI_API_KEY=sk-...                # Only if using OpenAI
    HOST=0.0.0.0                         # Leave as is for Docker
    PORT=8000                            # Change if needed
    ```

    ### Accessing Services

    - Morphik API: http://localhost:8000
    - API Documentation: http://localhost:8000/docs
    - Health Check: http://localhost:8000/health

    ### Troubleshooting

    1. **Service Won't Start**
       ```bash
       # View all logs
       docker compose logs
       
       # View specific service logs
       docker compose logs databridge
       docker compose logs postgres
       docker compose logs ollama
       ```

    2. **Database Issues**
       - Check PostgreSQL is healthy: `docker compose ps`
       - Verify database connection: `docker compose exec postgres psql -U databridge -d databridge`

    3. **Model Download Issues**
       - Check Ollama logs: `docker compose logs ollama`
       - Ensure enough disk space for models
       - Try restarting Ollama: `docker compose restart ollama`

    4. **Ollama Memory Issues**
       - If you see errors like "model requires more system memory than is available" in the logs:
         - Increase Docker memory allocation in Docker Desktop:
           1. Open Docker Desktop application
           2. Click on Settings (gear icon)
           3. Go to "Resources" section
           4. Increase memory allocation to at least 6GB (8GB recommended)
           5. Click "Apply & Restart"
         - Alternatively, modify `databridge.toml` to use a smaller model
         - Or switch to OpenAI API by uncommenting the OpenAI sections in `databridge.toml`
       - For knowledge graph creation specifically, you can switch from Ollama to OpenAI:
         ```toml
         # Change this section in databridge.toml
         [graph]
         provider = "openai"
         model_name = "gpt-4o-mini"
         enable_entity_resolution = true
         ```

    5. **Performance Issues**
       - Monitor resources: `docker stats`
       - Ensure sufficient RAM (8GB+ recommended)
       - Check disk space: `df -h`
  </Tab>
</Tabs>

## Next Steps

Now that you have the server running, you can explore the different ways to interact with the server.

<CardGroup cols={2}>
<Card icon="gear" title="Configure Morphik" href="/configuration">
  Configure Morphik using the `databridge.toml` file.
</Card>
<Card icon="code" title="API" href="/api-reference/ingest-text">
  Use the API to interact with the server.
</Card>
<Card icon="python" title="Python SDK" href="/python-sdk/introduction">
  Use the Python SDK to interact with the server.
</Card>
<Card icon="react"title="Morphik UI and CLI" href="/web-interface/introduction">
  Use the Morphik UI or CLI to interact with the server.
</Card>
</CardGroup>