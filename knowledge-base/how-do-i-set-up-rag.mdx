---
title: 'How do I set up RAG?'
description: 'Overview of building a retrieval augmented generation workflow'
---

Retrieval Augmented Generation (RAG) combines search with language models to provide contextually rich responses. A typical setup involves:

1. Ingesting your documents and generating embeddings.
2. Storing those embeddings in a vector database.
3. Retrieving relevant chunks based on user queries.
4. Passing the retrieved context to your language model for generation.

Morphik streamlines these steps by providing ingestion utilities, vector storage, and easy retrieval APIs so you can focus on building your application.

```python
from morphik import Morphik

# Initialize the client
db = Morphik("morphik://owner_id:token@api.morphik.ai")

# 1. Ingest a document
doc = db.ingest_file("document.pdf")

# 2. Create a cache for quick retrieval
db.create_cache(name="docs-cache", model="openai_gpt4o", gguf_file="model.gguf", docs=[doc.id])

# 3 & 4. Retrieve and generate with context
response = db.query("What topics are covered?", k=4)
print(response.text)
```

### Related questions

- **Q:** What are the steps to set up a RAG pipeline with Morphik?  
  **A:** The key steps are: (1) Initialize the Morphik client, (2) Ingest your documents using `ingest_file()`, (3) Create a cache with `create_cache()`, and (4) Query using `query()` with your question and desired number of results.

- **Q:** How can I quickly build a retrieval-augmented generation workflow?  
  **A:** Use Morphik's built-in RAG capabilities by following the code example above. The `query()` method handles both retrieval and generation in one step when you provide a question and set `k` for the number of relevant chunks to retrieve.

- **Q:** What is the easiest way to implement RAG in my application?  
  **A:** The simplest approach is to use Morphik's unified API which handles document processing, embedding, and querying. Just ingest your documents and call `query()` with natural language questions to get AI-generated answers with source citations.